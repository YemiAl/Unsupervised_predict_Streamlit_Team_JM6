{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-25T11:20:37.204945Z","iopub.execute_input":"2022-07-25T11:20:37.205366Z","iopub.status.idle":"2022-07-25T11:20:37.239068Z","shell.execute_reply.started":"2022-07-25T11:20:37.205279Z","shell.execute_reply":"2022-07-25T11:20:37.237932Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Climate Change Classification Predict Solution\n\n### Honour Code\n\nI {**TEAM_JM1**}, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the [EDSA honour code](https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n\nNon-compliance with the honour code constitutes a material breach of contract.\n\n### Predict Overview: Movie Recommendation System\n\nRecommender systems are socially and economically critical to ensure that individuals can make optimised choices surrounding the content they engage with on a daily basis. Hence, providing an accurate and robust solution to this challenge has immense economic potential, with users of the system being personalised recommendations . Our team has been tasked to:\n\n- 1. analyse the supplied data;\n- 2. clean the text data provided;\n- 3. determine if additional features can be added to enrich the data set;\n- 4. build a model that is capable of recommending a movie to a new user or continual user based on their consumption patterns;\n- 5. evaluate the accuracy of the best machine learning model;\n- 6. determine what features were most important in the modelâ€™s prediction decision, and\n- 7. explain the inner working of the model to a non-technical audience.","metadata":{}},{"cell_type":"markdown","source":"<a id =\"cont\"></a>\n\n## Table of Contents\n\n<a href=#one>1. Importing Packages</a>\n\n<a href=#four>4. Exploratory Data Analysis (EDA)</a>\n\n<a href=#five>5. Data Engineering</a>\n\n<a href=#six>6. Modeling</a>\n\n<a href=#seven>7. Model Performance</a>\n\n<a href=#eight>8. Model Explanations</a>\n\n<a href=#nine>9. Model Submission</a>","metadata":{"execution":{"iopub.status.busy":"2022-07-24T22:54:15.653079Z","iopub.execute_input":"2022-07-24T22:54:15.655301Z","iopub.status.idle":"2022-07-24T22:54:15.714879Z","shell.execute_reply.started":"2022-07-24T22:54:15.654753Z","shell.execute_reply":"2022-07-24T22:54:15.712511Z"}}},{"cell_type":"markdown","source":"## Connect to Comet","metadata":{}},{"cell_type":"markdown","source":"We will use the Comet platform as a version control platform for this project. We will start an experiment that will record the whole process of our model deployement.","metadata":{}},{"cell_type":"code","source":"# # Import comet_ml at the top of your file\n# from comet_ml import Experiment\n\n# # Create an experiment with your api key\n# experiment = Experiment(\n#     api_key=\"914jqxof7HD2vT3iISOxY4IkM\",\n#     project_name=\"team-jm6\",\n#     workspace=\"oluyemi\",\n# )\n\n# # Run your code and go to /","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:20:37.240868Z","iopub.execute_input":"2022-07-25T11:20:37.241164Z","iopub.status.idle":"2022-07-25T11:20:37.245939Z","shell.execute_reply.started":"2022-07-25T11:20:37.241137Z","shell.execute_reply":"2022-07-25T11:20:37.244924Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":" <a id=\"one\"></a>\n## 1. Importing Packages\n<a href=#cont>Back to Table of Contents</a>\n","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy as sp\nfrom wordcloud import WordCloud, STOPWORDS\nimport os      \nimport surprise\nfrom surprise import Reader\nfrom surprise import Dataset\nfrom surprise.model_selection import train_test_split\nimport time\nfrom surprise import SVD\nfrom surprise import accuracy\nimport re\nimport plotly.express as px\nimport scipy as sp\nfrom wordcloud import WordCloud, STOPWORDS\nfrom surprise import Reader\nfrom surprise import Dataset\nfrom surprise.model_selection import cross_validate\nfrom surprise import NormalPredictor\nfrom surprise import KNNBasic\nfrom surprise import KNNWithMeans\nfrom surprise import KNNWithZScore\nfrom surprise import KNNBaseline\nfrom surprise import BaselineOnly\nfrom surprise import SVDpp\nfrom surprise import NMF\nfrom surprise import SlopeOne\nfrom surprise import CoClustering\nfrom surprise.accuracy import rmse\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline  import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures, Normalizer\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge\nfrom catboost import CatBoostRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.manifold import TSNE","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:20:37.248279Z","iopub.execute_input":"2022-07-25T11:20:37.249273Z","iopub.status.idle":"2022-07-25T11:20:39.731626Z","shell.execute_reply.started":"2022-07-25T11:20:37.249241Z","shell.execute_reply":"2022-07-25T11:20:39.730740Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"The required movie data and metadata has been provided and will be loaded for the purpose of our model building","metadata":{}},{"cell_type":"code","source":"#Loading all required files into dataframes\ntrain_df = pd.read_csv('/kaggle/input/edsa-movie-recommendation-2022/train.csv')\ntest_df = pd.read_csv('/kaggle/input/edsa-movie-recommendation-2022/test.csv')\ntags_df = pd.read_csv('/kaggle/input/edsa-movie-recommendation-2022/tags.csv')\nmovies_df = pd.read_csv('/kaggle/input/edsa-movie-recommendation-2022/movies.csv')\nlinks_df = pd.read_csv('/kaggle/input/edsa-movie-recommendation-2022/links.csv')\nimdb_df = pd.read_csv('/kaggle/input/edsa-movie-recommendation-2022/imdb_data.csv')\ngenome_tags = pd.read_csv('/kaggle/input/edsa-movie-recommendation-2022/genome_tags.csv')\ngenome_score = pd.read_csv('/kaggle/input/edsa-movie-recommendation-2022/genome_scores.csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:20:39.733559Z","iopub.execute_input":"2022-07-25T11:20:39.734320Z","iopub.status.idle":"2022-07-25T11:20:55.969395Z","shell.execute_reply.started":"2022-07-25T11:20:39.734287Z","shell.execute_reply":"2022-07-25T11:20:55.968359Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# #Creating a Summary function\n# def Summary(df):\n#     return df.info()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:20:55.970536Z","iopub.execute_input":"2022-07-25T11:20:55.970835Z","iopub.status.idle":"2022-07-25T11:20:55.974524Z","shell.execute_reply.started":"2022-07-25T11:20:55.970810Z","shell.execute_reply":"2022-07-25T11:20:55.973801Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"We will take a look at our **train** data and also our **movies** data","metadata":{}},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:20:55.975467Z","iopub.execute_input":"2022-07-25T11:20:55.976397Z","iopub.status.idle":"2022-07-25T11:20:56.009122Z","shell.execute_reply.started":"2022-07-25T11:20:55.976365Z","shell.execute_reply":"2022-07-25T11:20:56.007770Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#Displaying the top 5 items in our train dataset\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:20:56.010596Z","iopub.execute_input":"2022-07-25T11:20:56.010943Z","iopub.status.idle":"2022-07-25T11:20:56.037277Z","shell.execute_reply.started":"2022-07-25T11:20:56.010899Z","shell.execute_reply":"2022-07-25T11:20:56.036148Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Created a Data Frame outlining the size of our data\ndataframes = ['train_df', 'test_df', 'tags_df', 'imdb_df',\n              'links_df', 'movies_df', 'genome_tags', 'genome_score']\nsizes = [len(train_df), len(test_df), len(tags_df),\n         len(imdb_df), len(links_df), len(movies_df),\n         len(genome_tags), len(genome_score)]\ntotal_size_df = pd.DataFrame(list(zip(dataframes, sizes)),\n                             columns=['dataframe', 'sizes'])\ntotal_size_df","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:20:56.038855Z","iopub.execute_input":"2022-07-25T11:20:56.039859Z","iopub.status.idle":"2022-07-25T11:20:56.052667Z","shell.execute_reply.started":"2022-07-25T11:20:56.039823Z","shell.execute_reply":"2022-07-25T11:20:56.051555Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"From the sizes of the different datasets available, it is evident how huge our task mayy be. The dataframe sizes would require resource intensive operations that we have to keep in mind. ","metadata":{}},{"cell_type":"code","source":"total_size_df = total_size_df[total_size_df['sizes'] > 100000]\ntotal_size_df","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:20:56.054399Z","iopub.execute_input":"2022-07-25T11:20:56.054988Z","iopub.status.idle":"2022-07-25T11:20:56.073478Z","shell.execute_reply.started":"2022-07-25T11:20:56.054940Z","shell.execute_reply":"2022-07-25T11:20:56.072267Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"new_row = {'dataframe': 'other', 'sizes': 180530}\ntotal_size_df = total_size_df.append(new_row,\n                                     ignore_index=True)\ntotal_size_df","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:20:56.078041Z","iopub.execute_input":"2022-07-25T11:20:56.078377Z","iopub.status.idle":"2022-07-25T11:20:56.092674Z","shell.execute_reply.started":"2022-07-25T11:20:56.078351Z","shell.execute_reply":"2022-07-25T11:20:56.091453Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"four\"></a>\n## 4. Exploratory Data Analysis (EDA)\n<a class=\"anchor\" id=\"1.1\"></a>\n<a href=#cont>Back to Table of Contents</a>\n","metadata":{}},{"cell_type":"code","source":"explodeTuple = (0.05, 0.04, 0.05, 0.04, 0.6)\nfig1, ax1 = plt.subplots(figsize=(14,7))\nax1.pie(total_size_df['sizes'].values,\n        labels=total_size_df['dataframe'].values,\n        startangle=90, autopct='%1.1f%%',\n        explode=explodeTuple)\nax1.axis('equal')\nplt.title('Distribution of overall Data Frames')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:20:56.093860Z","iopub.execute_input":"2022-07-25T11:20:56.094351Z","iopub.status.idle":"2022-07-25T11:20:56.301679Z","shell.execute_reply.started":"2022-07-25T11:20:56.094315Z","shell.execute_reply":"2022-07-25T11:20:56.300187Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"len_list = [['train_df', len(train_df)], ['tags_df', len(tags_df)],\n            ['imdb_df', len(imdb_df)], ['links_df', len(links_df)],\n            ['movies_df', len(movies_df)],\n            ['genome_tags', len(genome_tags)],\n            ['genome_score', len(genome_score)]]\nlen_df = pd.DataFrame(len_list,\n                      columns=['Dataset', 'Size'])\nfig = px.bar(len_df, x=len_df['Dataset'],\n             y=len_df['Size'],\n             color=len_df['Dataset'],\n             title='Distribution of overall Data Frames')\nfig.update_layout(legend=dict(\n    orientation=\"h\",\n    yanchor=\"bottom\",\n    y=1.02,\n    xanchor=\"right\",\n    x=1\n))\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:20:56.303506Z","iopub.execute_input":"2022-07-25T11:20:56.304582Z","iopub.status.idle":"2022-07-25T11:20:57.503873Z","shell.execute_reply.started":"2022-07-25T11:20:56.304528Z","shell.execute_reply":"2022-07-25T11:20:57.502832Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"We will take a look at the the datasets  available and check for any null values present.","metadata":{}},{"cell_type":"code","source":"# Obtaining the total null values in each Data Frames columns\ntrain_count = pd.DataFrame(train_df.isnull().sum())\ntest_count = pd.DataFrame(test_df.isnull().sum())\ntags_count = pd.DataFrame(tags_df.isnull().sum())\nmovies_count = pd.DataFrame(movies_df.isnull().sum())\nlinks_count = pd.DataFrame(links_df.isnull().sum())\nimdb_count = pd.DataFrame(imdb_df.isnull().sum())\ngenomet_count = pd.DataFrame(genome_tags.isnull().sum())\ngenomes_count = pd.DataFrame(genome_score.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:20:57.505245Z","iopub.execute_input":"2022-07-25T11:20:57.505935Z","iopub.status.idle":"2022-07-25T11:20:57.733743Z","shell.execute_reply.started":"2022-07-25T11:20:57.505901Z","shell.execute_reply":"2022-07-25T11:20:57.732608Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_count","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:20:57.735330Z","iopub.execute_input":"2022-07-25T11:20:57.736060Z","iopub.status.idle":"2022-07-25T11:20:57.743815Z","shell.execute_reply.started":"2022-07-25T11:20:57.735974Z","shell.execute_reply":"2022-07-25T11:20:57.742836Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"test_count","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:20:57.746986Z","iopub.execute_input":"2022-07-25T11:20:57.747683Z","iopub.status.idle":"2022-07-25T11:20:57.759682Z","shell.execute_reply.started":"2022-07-25T11:20:57.747650Z","shell.execute_reply":"2022-07-25T11:20:57.758498Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"plt.bar(tags_count.index,\n        tags_count.values.reshape(len(tags_count), ),\n        color='red')\nplt.xlabel('column_name')\nplt.ylabel('count')\nplt.title('Null value count in tags_df')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:20:57.761113Z","iopub.execute_input":"2022-07-25T11:20:57.762261Z","iopub.status.idle":"2022-07-25T11:20:57.938808Z","shell.execute_reply.started":"2022-07-25T11:20:57.762215Z","shell.execute_reply":"2022-07-25T11:20:57.937461Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing common users\n\n","metadata":{}},{"cell_type":"code","source":"# To find the number of times a user rated a movie, we create a data frame with the count by userId\ntrain_user = pd.DataFrame(\n   \n    train_df['userId'].value_counts()\n\n).reset_index()\n\ntrain_user.rename(columns={'index':'userId','userId':'count'},\n                  inplace=True)\ntrain_user.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:20:57.940126Z","iopub.execute_input":"2022-07-25T11:20:57.940468Z","iopub.status.idle":"2022-07-25T11:20:58.452507Z","shell.execute_reply.started":"2022-07-25T11:20:57.940399Z","shell.execute_reply":"2022-07-25T11:20:58.451421Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Grouping the users within a certain range aided us in determining the common userId's and the new ones.\ngroup_one = train_user.loc[(train_user['count'] > 0) & \n            (train_user['count'] < 50),\n            'userId'].value_counts().sum()\ngroup_two = train_user.loc[(train_user['count'] >= 50) & \n            (train_user['count'] < 500),\n            'userId'].value_counts().sum()\ngroup_three = train_user.loc[(train_user['count'] >= 500) & \n            (train_user['count'] < 1000),\n            'userId'].value_counts().sum()\ngroup_four = train_user.loc[(train_user['count'] >= 1000) & \n            (train_user['count'] < 1500),\n            'userId'].value_counts().sum()\ngroup_five = train_user.loc[(train_user['count'] >= 1500),\n            'userId'].value_counts().sum()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:20:58.453801Z","iopub.execute_input":"2022-07-25T11:20:58.454514Z","iopub.status.idle":"2022-07-25T11:20:58.490891Z","shell.execute_reply.started":"2022-07-25T11:20:58.454474Z","shell.execute_reply":"2022-07-25T11:20:58.489915Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# To give us insight in the spread, we used figures to determine the spread.\ntrial_error = np.array([['group_one', group_one,\n                         'between 1 and 50'],\n                        ['group_two', group_two,\n                         'between 50 and 500'],\n                        ['group_three', group_three,\n                         'between 500 and 1000'],\n                        ['group_four', group_four,\n                         'between 1000 and 1500'],\n                        ['group_five', group_five,\n                         'greater than 1500']])\ntrial_error_df = pd.DataFrame({'group': trial_error[:, 0],\n                               'userId_grouping': trial_error[:, 1],\n                               'explanation': trial_error[:, 2]})\nfig = px.bar(trial_error_df,\n             x=trial_error_df[\"group\"],\n             y=trial_error_df[\"userId_grouping\"],\n             color=trial_error_df[\"group\"],\n             title='Grouped Rating Distribustion')\nfig.update_layout(legend=dict(\n    orientation=\"h\",\n    yanchor=\"bottom\",\n    y=1.02,\n    xanchor=\"right\",\n    x=1\n))\nfig.show()\ntrial_error_df","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:20:58.492092Z","iopub.execute_input":"2022-07-25T11:20:58.492854Z","iopub.status.idle":"2022-07-25T11:20:58.572743Z","shell.execute_reply.started":"2022-07-25T11:20:58.492823Z","shell.execute_reply":"2022-07-25T11:20:58.571739Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def user_ratings_count(df, n):\n    plt.figure(figsize=(14,7))\n    data = df['userId'].value_counts().head(n)\n    ax = sns.barplot(x = data.index, y = data, order= data.index, palette='CMRmap', edgecolor=\"black\")\n    for p in ax.patches:\n        ax.text(p.get_x() + p.get_width()/2., p.get_height(), '%d' % int(p.get_height()), fontsize=11, ha='center', va='bottom')\n    plt.title(f'Top {n} Users by Number of Ratings', fontsize=14)\n    plt.xlabel('User ID')\n    plt.ylabel('Number of Ratings')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:20:58.574346Z","iopub.execute_input":"2022-07-25T11:20:58.574686Z","iopub.status.idle":"2022-07-25T11:20:58.581929Z","shell.execute_reply.started":"2022-07-25T11:20:58.574658Z","shell.execute_reply":"2022-07-25T11:20:58.580666Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"user_ratings_count(train_df,10)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:20:58.583468Z","iopub.execute_input":"2022-07-25T11:20:58.583804Z","iopub.status.idle":"2022-07-25T11:20:59.343032Z","shell.execute_reply.started":"2022-07-25T11:20:58.583773Z","shell.execute_reply":"2022-07-25T11:20:59.341774Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### Exploring Movie Genres","metadata":{}},{"cell_type":"code","source":"genres = pd.DataFrame(movies_df['genres'].\n                      str.split(\"|\").\n                      tolist(),\n                      index=movies_df['movieId']).stack()\ngenres = genres.reset_index([0, 'movieId'])\ngenres.columns = ['movieId', 'Genre']\ngenres.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:20:59.345440Z","iopub.execute_input":"2022-07-25T11:20:59.346245Z","iopub.status.idle":"2022-07-25T11:20:59.607558Z","shell.execute_reply.started":"2022-07-25T11:20:59.346197Z","shell.execute_reply":"2022-07-25T11:20:59.606669Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(14, 7))\nsns.countplot(x='Genre',\n              data=genres,\n              palette='CMRmap',\n              order=genres['Genre'].\n              value_counts().index)\nplt.xticks(rotation=90)\nplt.xlabel('Genre', size=20)\nplt.ylabel('Count', size=20)\nplt.title('Distribution of Movie Genres', size=25)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:20:59.608861Z","iopub.execute_input":"2022-07-25T11:20:59.609219Z","iopub.status.idle":"2022-07-25T11:20:59.979816Z","shell.execute_reply.started":"2022-07-25T11:20:59.609190Z","shell.execute_reply":"2022-07-25T11:20:59.978562Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"### Exploring the Movies Data","metadata":{}},{"cell_type":"code","source":"movies=pd.merge(train_df, movies_df,on='movieId',how='inner')\nmovies.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:20:59.981100Z","iopub.execute_input":"2022-07-25T11:20:59.981386Z","iopub.status.idle":"2022-07-25T11:21:02.256296Z","shell.execute_reply.started":"2022-07-25T11:20:59.981362Z","shell.execute_reply":"2022-07-25T11:21:02.255186Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"full_movies = pd.merge(movies,imdb_df,on='movieId',how='inner')\nfull_movies.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:21:02.257979Z","iopub.execute_input":"2022-07-25T11:21:02.259070Z","iopub.status.idle":"2022-07-25T11:21:04.712216Z","shell.execute_reply.started":"2022-07-25T11:21:02.259025Z","shell.execute_reply":"2022-07-25T11:21:04.711129Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"Let's look at the movies that received recieved that most individual ratings from users","metadata":{}},{"cell_type":"code","source":"def top_n_plot_by_ratings(df,column, n):\n    '''\n    This function takes in a dataframe, a columns(mostly a movie title column) and a number(The number of top movies to include in visualisation), computes\n    and display the top n movie by number of ratings received \n    '''\n    plt.figure(figsize=(14,7))\n    data = df[str(column)].value_counts().head(n)\n    ax = sns.barplot(x = data.index, y = data, order= data.index, palette='CMRmap', edgecolor=\"black\")\n    for p in ax.patches:\n        ax.text(p.get_x() + p.get_width()/2., p.get_height(), '%d' % int(p.get_height()), fontsize=11, ha='center', va='bottom')\n    plt.title(f'Top {n} {column.title()} by Number of Ratings', fontsize=14)\n    plt.xlabel(column.title())\n    plt.ylabel('Number of Ratings')\n    plt.xticks(rotation=90)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:21:04.713674Z","iopub.execute_input":"2022-07-25T11:21:04.714005Z","iopub.status.idle":"2022-07-25T11:21:04.722655Z","shell.execute_reply.started":"2022-07-25T11:21:04.713975Z","shell.execute_reply":"2022-07-25T11:21:04.721232Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"#Top 15 movies by number of ratings received\ntop_n_plot_by_ratings(movies,'title',15)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:21:04.724397Z","iopub.execute_input":"2022-07-25T11:21:04.724899Z","iopub.status.idle":"2022-07-25T11:21:05.508811Z","shell.execute_reply.started":"2022-07-25T11:21:04.724854Z","shell.execute_reply":"2022-07-25T11:21:05.507750Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Wordcloud of movie titles\nmovies_word = movies_df['title'] = movies_df['title'].astype('str')\nmovies_wordcloud = ' '.join(movies_word)\ntitle_wordcloud = WordCloud(stopwords = STOPWORDS,\n                            background_color = 'White',\n                            height = 1200,\n                            width = 900).generate(movies_wordcloud)\nplt.figure(figsize = (14,7), facecolor=None)\nplt.imshow(title_wordcloud)\nplt.axis('off')\nplt.title('Distribution of words from movie titles')\nplt.tight_layout(pad=0)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:21:05.513206Z","iopub.execute_input":"2022-07-25T11:21:05.513533Z","iopub.status.idle":"2022-07-25T11:21:09.781684Z","shell.execute_reply.started":"2022-07-25T11:21:05.513506Z","shell.execute_reply":"2022-07-25T11:21:09.780550Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"top_n_plot_by_ratings(movies,'rating',10)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:21:09.783199Z","iopub.execute_input":"2022-07-25T11:21:09.783553Z","iopub.status.idle":"2022-07-25T11:21:10.135895Z","shell.execute_reply.started":"2022-07-25T11:21:09.783521Z","shell.execute_reply":"2022-07-25T11:21:10.134758Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"top_n_plot_by_ratings(full_movies,'director',15)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:21:10.137130Z","iopub.execute_input":"2022-07-25T11:21:10.137721Z","iopub.status.idle":"2022-07-25T11:21:10.783676Z","shell.execute_reply.started":"2022-07-25T11:21:10.137685Z","shell.execute_reply":"2022-07-25T11:21:10.782442Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"Now we want to look at the distribution of the ratings provided. We want to see which percentage of the total ratings provided by users does a particular rating take up.i.e The number of users per any Rating.","metadata":{}},{"cell_type":"code","source":"movieRatingDistGroup = train_df['rating'].value_counts().sort_index().reset_index()\nfig, ax = plt.subplots(figsize=(14,7))\nsns.barplot(data=movieRatingDistGroup, x='index', y='rating', palette=\"CMRmap\", edgecolor=\"black\", ax=ax)\nax.set_xlabel(\"Rating\")\nax.set_ylabel('Number of Users')\nax.set_yticklabels(['{:,}'.format(int(x)) for x in ax.get_yticks().tolist()])\ntotal = float(movieRatingDistGroup['rating'].sum())\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()/2., height+350, '{0:.2%}'.format(height/total), fontsize=11, ha=\"center\", va='bottom')\nplt.title('Number of Users Per Rating', fontsize=14)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T11:58:14.189083Z","iopub.execute_input":"2022-07-25T11:58:14.190995Z","iopub.status.idle":"2022-07-25T11:58:14.589910Z","shell.execute_reply.started":"2022-07-25T11:58:14.190925Z","shell.execute_reply":"2022-07-25T11:58:14.588575Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def count_directors(df, count = 10):\n    \"\"\"\n    Function to count the most common dircetors in a DataFrame:\n    Parameters\n    ----------\n        df (DataFrame): input dataframe containing imdb metadata\n        count (int): filter directors with fewer than count films\n        \n    Returns\n    -------\n        directors (DataFrame): output DataFrame\n    Examples\n    --------\n        >>> df = pd.DataFrame({'imdbid':[0,1,2,3,4,5], 'director': [A,B,A,C,B]})\n        >>> count_directors(df, count = 1)\n            |index|director|count|\n            |0|A|2|\n            |1|B|2|\n            |2|C|1|\n    \"\"\"\n    directors = pd.DataFrame(df['director'].value_counts()).reset_index()\n    directors.columns = ['director', 'count']\n    # Lets only take directors who have made 10 or more movies otherwise we will have to analyze 11000 directors\n    directors = directors[directors['count']>=count]\n    return directors.sort_values('count', ascending = False)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T12:17:01.881818Z","iopub.execute_input":"2022-07-25T12:17:01.882204Z","iopub.status.idle":"2022-07-25T12:17:01.889963Z","shell.execute_reply.started":"2022-07-25T12:17:01.882173Z","shell.execute_reply":"2022-07-25T12:17:01.888759Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def feature_count(df, column):\n    plt.figure(figsize=(14,7))\n    ax = sns.barplot(x = df[f'{column}'], y= df['count'], palette='brg')\n    for p in ax.patches:\n        ax.text(p.get_x() + p.get_width()/2., p.get_height(), '%d' % int(p.get_height()), fontsize=11, ha='center', va='bottom')\n    plt.title(f'Number of Movies Per {column}', fontsize=14)\n    plt.xlabel(f'{column}')\n    plt.ylabel('Count')\n    plt.xticks(rotation=90)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T12:17:08.264318Z","iopub.execute_input":"2022-07-25T12:17:08.264776Z","iopub.status.idle":"2022-07-25T12:17:08.273114Z","shell.execute_reply.started":"2022-07-25T12:17:08.264729Z","shell.execute_reply":"2022-07-25T12:17:08.271762Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"directors = count_directors(imdb_df)\nfeature_count(directors.head(15), 'director')","metadata":{"execution":{"iopub.status.busy":"2022-07-25T12:49:23.315720Z","iopub.execute_input":"2022-07-25T12:49:23.316207Z","iopub.status.idle":"2022-07-25T12:49:23.660284Z","shell.execute_reply.started":"2022-07-25T12:49:23.316170Z","shell.execute_reply":"2022-07-25T12:49:23.659067Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"feature_count(directors[directors['director']!='See full summary'].head(15), 'director')","metadata":{"execution":{"iopub.status.busy":"2022-07-17T14:02:50.683448Z","iopub.execute_input":"2022-07-17T14:02:50.684225Z","iopub.status.idle":"2022-07-17T14:02:51.013933Z","shell.execute_reply.started":"2022-07-17T14:02:50.68417Z","shell.execute_reply":"2022-07-17T14:02:51.012714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Word Clouds","metadata":{}},{"cell_type":"code","source":"comment_words = ''\nstopwords = set(STOPWORDS)\n\n# iterate through the csv file\nfor val in tags_df['tag']:\n\n    # typecaste each val to string\n    val = str(val)\n\n    # split the value\n    tokens = val.split()\n\n    # Converts each token into lowercase\n    for i in range(len(tokens)):\n        tokens[i] = tokens[i].lower()\n\n    comment_words += \" \".join(tokens)+\" \"\n  \nwordcloud = WordCloud(width=1200, height=900,\n                      colormap='winter',\n                      background_color='white',\n                      stopwords=stopwords,collocations=False,\n                      min_font_size=10).generate(comment_words)\n\n# plot the WordCloud image\nplt.figure(figsize=(14, 7), facecolor=None)\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.title('Distribution of words in the tags data frame by Tags')\nplt.tight_layout(pad=0)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T12:55:13.089421Z","iopub.execute_input":"2022-07-25T12:55:13.089861Z","iopub.status.idle":"2022-07-25T12:55:20.395807Z","shell.execute_reply.started":"2022-07-25T12:55:13.089825Z","shell.execute_reply":"2022-07-25T12:55:20.394630Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"The WORDCLOUD here shows the most common words present in the tags dataset","metadata":{}},{"cell_type":"code","source":"#Total count of all \nvalue_count = pd.DataFrame(tags_df['tag'].\n                           value_counts()).reset_index()\nvalue_count.rename(columns = {'index': 'genre', 'tag': 'count'},\n                   inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T12:58:16.253126Z","iopub.execute_input":"2022-07-25T12:58:16.253825Z","iopub.status.idle":"2022-07-25T12:58:16.420830Z","shell.execute_reply.started":"2022-07-25T12:58:16.253790Z","shell.execute_reply":"2022-07-25T12:58:16.419685Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"value_count.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T12:58:18.069511Z","iopub.execute_input":"2022-07-25T12:58:18.070602Z","iopub.status.idle":"2022-07-25T12:58:18.081057Z","shell.execute_reply.started":"2022-07-25T12:58:18.070560Z","shell.execute_reply":"2022-07-25T12:58:18.080304Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"genre_count = value_count.head(20)\nplt.figure(figsize=(14,7))\nax = sns.barplot(x = genre_count['genre'], y= genre_count['count'], palette='CMRmap')\nfor p in ax.patches:\n        ax.text(p.get_x() + p.get_width()/2., p.get_height(), '%d' % int(p.get_height()), fontsize=11, ha='center', va='bottom')\nplt.title('Number of times a genre tag appears', fontsize=14)\nplt.xlabel('Genre tag')\nplt.ylabel('Genre tag Count')\nplt.xticks(rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-17T14:02:59.311337Z","iopub.execute_input":"2022-07-17T14:02:59.311661Z","iopub.status.idle":"2022-07-17T14:02:59.75269Z","shell.execute_reply.started":"2022-07-17T14:02:59.311634Z","shell.execute_reply":"2022-07-17T14:02:59.751465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Publishing Years","metadata":{}},{"cell_type":"code","source":"dates = []\nfor title in movies_df['title']:\n    if title[-1] == \" \":\n        year = title[-6: -2]\n        try:\n            dates.append(int(year))\n        except:\n            dates.append(9999)\n    else:\n        year = title[-5: -1]\n        try:\n            dates.append(int(year))\n        except:\n            dates.append(9999)\n\nmovies_df['Publish Year'] = dates","metadata":{"execution":{"iopub.status.busy":"2022-07-17T14:02:59.754312Z","iopub.execute_input":"2022-07-17T14:02:59.755599Z","iopub.status.idle":"2022-07-17T14:02:59.839808Z","shell.execute_reply.started":"2022-07-17T14:02:59.755547Z","shell.execute_reply":"2022-07-17T14:02:59.83856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dates = []\nfor title in movies_df['title']:\n    if title[-1] == \" \":\n        year = title[-6: -2]\n        try:\n            dates.append(int(year))\n        except:\n            dates.append(9999)\n    else:\n        year = title[-5: -1]\n        try:\n            dates.append(int(year))\n        except:\n            dates.append(9999)\n\nmovies_df['Publish Year'] = dates","metadata":{"execution":{"iopub.status.busy":"2022-07-17T14:02:59.841413Z","iopub.execute_input":"2022-07-17T14:02:59.841766Z","iopub.status.idle":"2022-07-17T14:02:59.928257Z","shell.execute_reply.started":"2022-07-17T14:02:59.841734Z","shell.execute_reply":"2022-07-17T14:02:59.927148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(movies_df)","metadata":{"execution":{"iopub.status.busy":"2022-07-17T14:02:59.930347Z","iopub.execute_input":"2022-07-17T14:02:59.930923Z","iopub.status.idle":"2022-07-17T14:02:59.938187Z","shell.execute_reply.started":"2022-07-17T14:02:59.93087Z","shell.execute_reply":"2022-07-17T14:02:59.936887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(movies_df[movies_df['Publish Year'] == 9999])","metadata":{"execution":{"iopub.status.busy":"2022-07-17T14:02:59.93968Z","iopub.execute_input":"2022-07-17T14:02:59.94003Z","iopub.status.idle":"2022-07-17T14:02:59.952937Z","shell.execute_reply.started":"2022-07-17T14:02:59.939999Z","shell.execute_reply":"2022-07-17T14:02:59.95173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movies_df[(movies_df['Publish Year'] > 1888) &\n          (movies_df['Publish Year'] < 2021)]","metadata":{"execution":{"iopub.status.busy":"2022-07-17T14:02:59.954012Z","iopub.execute_input":"2022-07-17T14:02:59.954717Z","iopub.status.idle":"2022-07-17T14:02:59.975544Z","shell.execute_reply.started":"2022-07-17T14:02:59.954685Z","shell.execute_reply":"2022-07-17T14:02:59.974385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = pd.DataFrame(movies_df['Publish Year'].\n                       value_counts()).reset_index()\ndataset.rename(columns={'index': 'year', 'Publish Year': 'count'},\n               inplace=True)\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-17T14:02:59.977031Z","iopub.execute_input":"2022-07-17T14:02:59.977794Z","iopub.status.idle":"2022-07-17T14:02:59.991369Z","shell.execute_reply.started":"2022-07-17T14:02:59.977759Z","shell.execute_reply":"2022-07-17T14:02:59.990237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"year_dataset = dataset[(dataset['year']>1888) & (dataset['year']<2021)].sort_values(by='count',ascending=False).head(50)\nplt.figure(figsize=(14,7))\nax = sns.barplot(x = year_dataset['year'], y= year_dataset['count'], order=year_dataset['year'], palette='CMRmap')\n#for p in ax.patches:\n#       ax.text(p.get_x() + p.get_width()/2., p.get_height(), '%d' % int(p.get_height()), fontsize=11, ha='center', va='bottom')\nplt.title('Number of Movies Released Per year', fontsize=14)\nplt.xlabel('year')\nplt.ylabel('Released Movie Count')\nplt.xticks(rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-17T14:02:59.992717Z","iopub.execute_input":"2022-07-17T14:02:59.993858Z","iopub.status.idle":"2022-07-17T14:03:00.74809Z","shell.execute_reply.started":"2022-07-17T14:02:59.993795Z","shell.execute_reply":"2022-07-17T14:03:00.746653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Budget","metadata":{}},{"cell_type":"code","source":"new_l = list(imdb_df['budget'])\nprint(type(new_l[9]))\n\nimdb_df['runtime'] = imdb_df['runtime'].fillna(imdb_df['runtime'].mean())\nimdb_df.isnull().sum() #data cleaning\nimdb_df.head()\nimdb_df['budget'] = imdb_df['budget'].str.replace('[\\,]', '', regex=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-17T14:03:00.749545Z","iopub.execute_input":"2022-07-17T14:03:00.750021Z","iopub.status.idle":"2022-07-17T14:03:00.788908Z","shell.execute_reply.started":"2022-07-17T14:03:00.749984Z","shell.execute_reply":"2022-07-17T14:03:00.788029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_txt(text):\n    text = re.sub(r'[0-9]+', \"\", str(text))\n    return text\nimdb_df['currency'] = imdb_df['budget'].apply(clean_txt)\nimdb_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-17T14:03:00.789971Z","iopub.execute_input":"2022-07-17T14:03:00.790968Z","iopub.status.idle":"2022-07-17T14:03:00.866469Z","shell.execute_reply.started":"2022-07-17T14:03:00.790934Z","shell.execute_reply":"2022-07-17T14:03:00.865581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"currencies = list(imdb_df['currency'])\n# Number of currencies\nlen(set(currencies))-1\n\ncurrencies_count_df = pd.DataFrame(imdb_df['currency'].\n                                   value_counts()).reset_index()\ncurrencies_count_df.rename(columns={'index': 'currency', 'currency': 'count'},\n                           inplace=True)\ncurrencies_count_df.head()\n\nfig = px.bar(currencies_count_df, x=currencies_count_df['currency'],\n             y=currencies_count_df['count'],\n             color=currencies_count_df['currency'],\n             title='Currency Type Distribution')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-17T14:03:00.867564Z","iopub.execute_input":"2022-07-17T14:03:00.868495Z","iopub.status.idle":"2022-07-17T14:03:01.191288Z","shell.execute_reply.started":"2022-07-17T14:03:00.868459Z","shell.execute_reply":"2022-07-17T14:03:01.190146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"def data_scaler(df):\n    \"\"\"\n    Scales data.\n    \"\"\"\n    scaler = StandardScaler(with_std=True)\n    scaled_data = scaler.fit_transform(df)\n    return scaled_data","metadata":{"execution":{"iopub.status.busy":"2022-07-21T13:29:03.673008Z","iopub.execute_input":"2022-07-21T13:29:03.673511Z","iopub.status.idle":"2022-07-21T13:29:03.681613Z","shell.execute_reply.started":"2022-07-21T13:29:03.673475Z","shell.execute_reply":"2022-07-21T13:29:03.680255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"genome= genome_score[:10000000]\ngenome","metadata":{"execution":{"iopub.status.busy":"2022-07-21T13:29:08.446102Z","iopub.execute_input":"2022-07-21T13:29:08.446559Z","iopub.status.idle":"2022-07-21T13:29:08.478338Z","shell.execute_reply.started":"2022-07-21T13:29:08.446525Z","shell.execute_reply":"2022-07-21T13:29:08.477496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaled_genome = data_scaler(genome.sample(frac=0.0001))","metadata":{"execution":{"iopub.status.busy":"2022-07-21T13:29:16.087795Z","iopub.execute_input":"2022-07-21T13:29:16.089239Z","iopub.status.idle":"2022-07-21T13:29:16.826902Z","shell.execute_reply.started":"2022-07-21T13:29:16.089198Z","shell.execute_reply":"2022-07-21T13:29:16.826121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tsne = TSNE(3, n_jobs = -1, verbose = 2, perplexity = 10, learning_rate = 0.1)\ntsne.fit(scaled_genome)","metadata":{"execution":{"iopub.status.busy":"2022-07-21T13:29:22.43653Z","iopub.execute_input":"2022-07-21T13:29:22.437863Z","iopub.status.idle":"2022-07-21T13:29:30.0522Z","shell.execute_reply.started":"2022-07-21T13:29:22.437774Z","shell.execute_reply":"2022-07-21T13:29:30.051327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Axes3D\n\nfig = plt.figure(figsize=(14, 7))\n\n# Add 3D scatter plot\nax = fig.add_subplot(projection='3d')\nax.scatter(tsne.embedding_[:,0], tsne.embedding_[:,1], tsne.embedding_[:,2])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-17T19:06:59.505867Z","iopub.execute_input":"2022-07-17T19:06:59.506328Z","iopub.status.idle":"2022-07-17T19:06:59.810798Z","shell.execute_reply.started":"2022-07-17T19:06:59.506289Z","shell.execute_reply":"2022-07-17T19:06:59.809959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(14, 7))\nsns.scatterplot(x = tsne.embedding_[:,0], y = tsne.embedding_[:,1], size=tsne.embedding_[:,2])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-17T14:04:20.00424Z","iopub.execute_input":"2022-07-17T14:04:20.004697Z","iopub.status.idle":"2022-07-17T14:04:20.354748Z","shell.execute_reply.started":"2022-07-17T14:04:20.004658Z","shell.execute_reply":"2022-07-17T14:04:20.353534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Below is the dataframe we will be altering.\nworking_train = train_df.drop(columns='timestamp')\nworking_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-21T13:30:12.199167Z","iopub.execute_input":"2022-07-21T13:30:12.200541Z","iopub.status.idle":"2022-07-21T13:30:12.367978Z","shell.execute_reply.started":"2022-07-21T13:30:12.200498Z","shell.execute_reply":"2022-07-21T13:30:12.366605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_work = working_train.set_index('movieId').join([movies_df[['movieId',\n                                                           'genres']]\n                                                   .set_index('movieId'),\n                                                   imdb_df[['movieId',\n                                                         'title_cast',\n                                                         'director',\n                                                         'plot_keywords']].\n                                                   set_index('movieId')],\n                                                  how='left').reset_index()\ndf_work.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-21T13:30:17.880266Z","iopub.execute_input":"2022-07-21T13:30:17.880676Z","iopub.status.idle":"2022-07-21T13:30:25.127581Z","shell.execute_reply.started":"2022-07-21T13:30:17.880645Z","shell.execute_reply":"2022-07-21T13:30:25.126372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-21T13:30:40.213827Z","iopub.execute_input":"2022-07-21T13:30:40.214171Z","iopub.status.idle":"2022-07-21T13:30:40.225148Z","shell.execute_reply.started":"2022-07-21T13:30:40.214141Z","shell.execute_reply":"2022-07-21T13:30:40.223728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocessor_train(df):\n    working_train = df.copy()\n\n    # Merge\n    df_work = working_train.set_index('movieId').join([movies_df\n                                                       [['movieId', 'genres']].\n                                                       set_index('movieId'),\n                                                       imdb_df[['movieId',\n                                                             'title_cast',\n                                                             'director',\n                                                             'plot_keywords']].\n                                                       set_index('movieId')],\n                                                      how='left').reset_index()\n\n# '(no genre listed)' is an equivalent of a missing value in the column genres\n\n    df_work['genres'] = ['' if x == '(no genres listed)' else x for x in df_work['genres']]\n\n    # filling missing values with 'nothing'... (emptying...?)\n    df_work.fillna('', inplace=True)\n\n    for col in df_work.select_dtypes('object').columns: # selecting 'object' columns\n\n        # removing white space\n        df_work[col] = [''.join(x.split()) for x in df_work[col]]\n\n        # substituting '|' with a white space\n        df_work[col] = [' '.join(x.split('|')) for x in df_work[col]]\n\n    # joining the features of interest\n    df_work['corpus'] =  df_work[df_work.select_dtypes('object').columns].apply(lambda x: ' '.join(x), axis=1)\n    return df_work[['movieId', 'userId', 'corpus', 'rating']]\n","metadata":{"execution":{"iopub.status.busy":"2022-07-21T13:30:47.978934Z","iopub.execute_input":"2022-07-21T13:30:47.979376Z","iopub.status.idle":"2022-07-21T13:30:47.992372Z","shell.execute_reply.started":"2022-07-21T13:30:47.979341Z","shell.execute_reply":"2022-07-21T13:30:47.990907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocessor_test(df):\n    working_train = df.copy()\n\n    # Merge\n    df_work = working_train.set_index('movieId').join([movies_df\n                                                       [['movieId', 'genres']].\n                                                       set_index('movieId'),\n                                                       imdb_df[['movieId',\n                                                             'title_cast',\n                                                             'director',\n                                                             'plot_keywords']].\n                                                       set_index('movieId')],\n                                                      how='left').reset_index()\n\n# '(no genre listed)' is an equivalent of a missing value in the column genres\n\n    df_work['genres'] = ['' if x == '(no genres listed)' else x for x in df_work['genres']]\n\n    # filling missing values with 'nothing'... (emptying...?)\n    df_work.fillna('', inplace=True)\n\n    for col in df_work.select_dtypes('object').columns: # selecting 'object' columns\n\n        # removing white space\n        df_work[col] = [''.join(x.split()) for x in df_work[col]]\n\n        # substituting '|' with a white space\n        df_work[col] = [' '.join(x.split('|')) for x in df_work[col]]\n\n    # joining the features of interest\n    df_work['corpus'] =  df_work[df_work.select_dtypes('object').columns].apply(lambda x: ' '.join(x), axis=1)\n    return df_work[['movieId', 'userId', 'corpus']]","metadata":{"execution":{"iopub.status.busy":"2022-07-21T13:30:57.35952Z","iopub.execute_input":"2022-07-21T13:30:57.360005Z","iopub.status.idle":"2022-07-21T13:30:57.371508Z","shell.execute_reply.started":"2022-07-21T13:30:57.359969Z","shell.execute_reply":"2022-07-21T13:30:57.370503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Test = preprocessor_test(test_df)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-21T13:31:33.900885Z","iopub.execute_input":"2022-07-21T13:31:33.901685Z","iopub.status.idle":"2022-07-21T13:33:16.820105Z","shell.execute_reply.started":"2022-07-21T13:31:33.901649Z","shell.execute_reply":"2022-07-21T13:33:16.818714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Test.info","metadata":{"execution":{"iopub.status.busy":"2022-07-21T13:33:25.775217Z","iopub.execute_input":"2022-07-21T13:33:25.775718Z","iopub.status.idle":"2022-07-21T13:33:25.788285Z","shell.execute_reply.started":"2022-07-21T13:33:25.775679Z","shell.execute_reply":"2022-07-21T13:33:25.787401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train = preprocessor_train(train_df.drop(columns=['timestamp'])) # DO NOT RUN THIS ON LOCAL COMPUTER","metadata":{"execution":{"iopub.status.busy":"2022-07-21T13:33:45.162437Z","iopub.execute_input":"2022-07-21T13:33:45.163131Z","iopub.status.idle":"2022-07-21T13:37:07.938452Z","shell.execute_reply.started":"2022-07-21T13:33:45.16308Z","shell.execute_reply":"2022-07-21T13:37:07.937204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_1 = Train.drop(columns=['rating', 'userId', 'movieId'])\nTest_1 = Test.drop(columns=['userId', 'movieId'])","metadata":{"execution":{"iopub.status.busy":"2022-07-21T13:52:20.753221Z","iopub.execute_input":"2022-07-21T13:52:20.754564Z","iopub.status.idle":"2022-07-21T13:52:21.562111Z","shell.execute_reply.started":"2022-07-21T13:52:20.75451Z","shell.execute_reply":"2022-07-21T13:52:21.560943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Test_1.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-21T13:52:25.812793Z","iopub.execute_input":"2022-07-21T13:52:25.814221Z","iopub.status.idle":"2022-07-21T13:52:25.821915Z","shell.execute_reply.started":"2022-07-21T13:52:25.814118Z","shell.execute_reply":"2022-07-21T13:52:25.821143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_1.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-20T01:06:15.634559Z","iopub.execute_input":"2022-07-20T01:06:15.635866Z","iopub.status.idle":"2022-07-20T01:06:15.643141Z","shell.execute_reply.started":"2022-07-20T01:06:15.635812Z","shell.execute_reply":"2022-07-20T01:06:15.641908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_1.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T01:06:20.883867Z","iopub.execute_input":"2022-07-20T01:06:20.884293Z","iopub.status.idle":"2022-07-20T01:06:20.897399Z","shell.execute_reply.started":"2022-07-20T01:06:20.88426Z","shell.execute_reply":"2022-07-20T01:06:20.896015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Test_1.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T01:06:23.528943Z","iopub.execute_input":"2022-07-20T01:06:23.529413Z","iopub.status.idle":"2022-07-20T01:06:23.540919Z","shell.execute_reply.started":"2022-07-20T01:06:23.529379Z","shell.execute_reply":"2022-07-20T01:06:23.539875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = Train['rating']","metadata":{"execution":{"iopub.status.busy":"2022-07-21T13:52:35.076667Z","iopub.execute_input":"2022-07-21T13:52:35.077139Z","iopub.status.idle":"2022-07-21T13:52:35.082291Z","shell.execute_reply.started":"2022-07-21T13:52:35.077104Z","shell.execute_reply":"2022-07-21T13:52:35.081395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv = CountVectorizer()\nTrain_mat =cv.fit_transform(Train_1['corpus'])","metadata":{"execution":{"iopub.status.busy":"2022-07-21T13:52:48.887663Z","iopub.execute_input":"2022-07-21T13:52:48.888526Z","iopub.status.idle":"2022-07-21T13:56:37.009085Z","shell.execute_reply.started":"2022-07-21T13:52:48.888486Z","shell.execute_reply":"2022-07-21T13:56:37.007492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Test_mat = cv.transform(Test_1['corpus'])","metadata":{"execution":{"iopub.status.busy":"2022-07-21T13:57:34.231149Z","iopub.execute_input":"2022-07-21T13:57:34.23259Z","iopub.status.idle":"2022-07-21T13:59:27.460804Z","shell.execute_reply.started":"2022-07-21T13:57:34.232529Z","shell.execute_reply":"2022-07-21T13:59:27.459595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_mat.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-21T14:00:09.484394Z","iopub.execute_input":"2022-07-21T14:00:09.484801Z","iopub.status.idle":"2022-07-21T14:00:09.49342Z","shell.execute_reply.started":"2022-07-21T14:00:09.484767Z","shell.execute_reply":"2022-07-21T14:00:09.49133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Test_mat.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-21T14:00:11.950051Z","iopub.execute_input":"2022-07-21T14:00:11.95051Z","iopub.status.idle":"2022-07-21T14:00:11.958593Z","shell.execute_reply.started":"2022-07-21T14:00:11.950477Z","shell.execute_reply":"2022-07-21T14:00:11.957534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modelling","metadata":{}},{"cell_type":"markdown","source":"### Content Based Filtering ","metadata":{}},{"cell_type":"markdown","source":"#### Linear Regression ","metadata":{}},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-07-17T16:45:03.011063Z","iopub.execute_input":"2022-07-17T16:45:03.011795Z","iopub.status.idle":"2022-07-17T16:45:03.118818Z","shell.execute_reply.started":"2022-07-17T16:45:03.011627Z","shell.execute_reply":"2022-07-17T16:45:03.117442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Collaborative Based Filtering","metadata":{}},{"cell_type":"code","source":"# Load the 1M dataset\ntrain_df.drop('timestamp', axis=1)\ntrain_subset = train_df[:1000000]\nreader = Reader(rating_scale=(train_subset['rating'].min(), train_subset['rating'].max()))\ndata = Dataset.load_from_df(train_subset[['userId', 'movieId', 'rating']], reader)\ntrainset, testset = train_test_split(data, test_size=.25, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-07-21T14:01:20.138812Z","iopub.execute_input":"2022-07-21T14:01:20.139497Z","iopub.status.idle":"2022-07-21T14:01:25.900274Z","shell.execute_reply.started":"2022-07-21T14:01:20.139458Z","shell.execute_reply":"2022-07-21T14:01:25.898931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-21T14:01:37.42922Z","iopub.execute_input":"2022-07-21T14:01:37.429741Z","iopub.status.idle":"2022-07-21T14:01:37.445276Z","shell.execute_reply.started":"2022-07-21T14:01:37.429698Z","shell.execute_reply":"2022-07-21T14:01:37.44387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-21T14:01:40.34588Z","iopub.execute_input":"2022-07-21T14:01:40.34658Z","iopub.status.idle":"2022-07-21T14:01:40.356723Z","shell.execute_reply.started":"2022-07-21T14:01:40.346542Z","shell.execute_reply":"2022-07-21T14:01:40.355171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Singular Value Decomposition (SVD)","metadata":{}},{"cell_type":"code","source":"svd_model = SVD(n_epochs=50,n_factors=400,init_std_dev=0.001,random_state=42,verbose=True)\nsvd_model.fit(trainset)\nsvd_predictions = svd_model.test(testset)\nsvd_rmse = accuracy.rmse(svd_predictions)","metadata":{"execution":{"iopub.status.busy":"2022-07-21T14:02:30.42282Z","iopub.execute_input":"2022-07-21T14:02:30.423931Z","iopub.status.idle":"2022-07-21T14:18:57.596179Z","shell.execute_reply.started":"2022-07-21T14:02:30.423887Z","shell.execute_reply":"2022-07-21T14:18:57.595003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dictionary for logging SVD model on comet\nparams = {'model_name': 'SVD'}\nmetrics = {'RMSE': svd_rmse}\n\n# Log the parameters and results for the SVD model\nexperiment.log_parameters(params)\nexperiment.log_parameters(metrics)\n# End the experiment for the SVD experiment\nexperiment.end()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"# Load the 1M dataset\ntrain_df.drop('timestamp', axis=1)\n#train_subset = train_df[:1000000] remove\nreader = Reader(rating_scale=(train_df['rating'].min(), train_df['rating'].max()))\ndata = Dataset.load_from_df(train_df[['userId', 'movieId', 'rating']], reader)\ntrainset, testset = train_test_split(data, test_size=.30, random_state=42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svd_model_hyper = SVD(n_epochs=50,n_factors=250,init_std_dev=0.001,random_state=42,verbose=True)\nsvd_model_hyper.fit(trainset)\nsvd_predictions_hyper = svd_model_hyper.test(testset)\nsvd_rmse_hyper = accuracy.rmse(svd_predictions_hyper)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dictionary for logging the tuned SVD model on comet\nparams = {'model_name': 'SVD'}\nmetrics = {'RMSE': svd_rmse_hyper}\n\n# Log the parameters and results for the SVD model\nexperiment.log_parameters(params)\nexperiment.log_parameters(metrics)\n# End the experiment for the SVD experiment\nexperiment.end()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Kaggle Submission","metadata":{}},{"cell_type":"code","source":"#svd_model = SVD(n_epochs=50,n_factors=400,init_std_dev=0.001,random_state=42,verbose=True)\n#svd_model.fit(trainset)\nsvd_predictions_test = svd_model.test(Test)\nsvd_rmse_test = accuracy.rmse(svd_predictions_test)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T02:59:23.033752Z","iopub.execute_input":"2022-07-20T02:59:23.034345Z","iopub.status.idle":"2022-07-20T02:59:23.069747Z","shell.execute_reply.started":"2022-07-20T02:59:23.034304Z","shell.execute_reply":"2022-07-20T02:59:23.068462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.userId=test_df['userId'].astype(int)\ntest_df.movieId=test_df['movieId'].astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T02:59:56.113898Z","iopub.execute_input":"2022-07-20T02:59:56.114404Z","iopub.status.idle":"2022-07-20T02:59:56.432466Z","shell.execute_reply.started":"2022-07-20T02:59:56.114366Z","shell.execute_reply":"2022-07-20T02:59:56.430945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['Id']=test_df.apply(lambda x:'%s_%s' % (x['userId'],x['movieId']),axis=1)\ntest_df['Id']=test_df.apply(lambda x:'%s_%s' % (x['userId'],x['movieId']),axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T03:00:09.615464Z","iopub.execute_input":"2022-07-20T03:00:09.615992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df[\"rating\"] = test_df.apply(\n    lambda x: svd_model.predict(x[\"userId\"], x[\"movieId\"]).est, axis=1\n)\nsubmission = test_df[[\"Id\", \"rating\"]]","metadata":{"execution":{"iopub.status.busy":"2022-07-20T00:20:31.258512Z","iopub.execute_input":"2022-07-20T00:20:31.258977Z","iopub.status.idle":"2022-07-20T00:23:17.173675Z","shell.execute_reply.started":"2022-07-20T00:20:31.258943Z","shell.execute_reply":"2022-07-20T00:23:17.172181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission3_svd.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T00:24:40.552369Z","iopub.execute_input":"2022-07-20T00:24:40.553181Z","iopub.status.idle":"2022-07-20T00:24:58.175891Z","shell.execute_reply.started":"2022-07-20T00:24:40.553142Z","shell.execute_reply":"2022-07-20T00:24:58.17473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}